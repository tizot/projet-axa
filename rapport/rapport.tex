\documentclass[a4paper,11pt,french]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{polytechnique}
\usepackage{booktabs}

\title{AXA data challenge}
\author{Basile \bsc{Bruneau}\\Camille \bsc{Masset}\\Denis \bsc{Merigoux}}

\begin{document}
    \maketitle

    \section{Actions effectuées}

    \subsection{Pre-processing}

        Nous avons effectué les actions suivantes pour pre-processer les données de \verb|train_2011_2012.csv| :
        \begin{itemize}
            \item remplacer toutes les colonnes contenant des chaînes de caractère par autant de colonnes différentes que de chaînes de caractères possibles ;
            \item remplacer les valeurs manquantes par la moyenne de tous les échantillons ;
            \item sélectionner uniquement les colonnes \verb|Date|, \verb|WEEK_END| et \verb|DAYS_WE_DS| ;
            \item ne garder que les lignes où $\verb|ASS_SOC_MERE|==\verb|'Entity1 France'|$ ;
            \item calculer pour chaque combinaison de créneau horaire et d'\verb|ASS_ASSIGNMENT|, la somme des \verb|CSPL_RECEIVED_CALLS| associés.
        \end{itemize}
        Pour les données météos, nous avons réorganisé le fichier CSV en donnant pour chaque créneau horaire la liste des \emph{features} météo dans chaque département. Les valeurs sont moyennées par département et par créneau horaire, et inféré les valeurs manquantes par moyennage.

    \subsection{Feature selection}
        Elle consiste en les actions suivantes :
        \begin{itemize}
            \item calcul des variances des colonnes (sauf la date) et choix des 30 variances les plus élevées ;
            \item analyse PCA.
        \end{itemize}

    \subsection{Learning algorithm}

    Pour effectuer nos prédictions et calculer un modèle, deux possibilités s'offraient à nous :
    \begin{itemize}
        \item effectuer une régression sur \verb|CSPL_RECEIVED_CALLS| ;
        \item effectuer une classification sur les données, un label étant une valeur de \verb|CSPL_RECEIVED_CALLS|.
    \end{itemize}
    Nous discuterons de ces deux possibilités dans la section \ref{discussion}.

    \subsection{Prédiction}

    Nous avons regroupé les lignes du fichier \verb|submission.txt| par dates et pour chacune de ces dates, nous réalisons un apprentissage sur les données passées et utilisons le modèle obtenu pour réaliser les prédictions.

    \section{Organisation du code}

    La plupart des scripts lisent des fichiers \verb|.csv| et écrivent d'autres fichier \verb|.csv|. On a le pipeline suivant :
    \begin{itemize}
        \item \verb|data_preprocessing.py| lit le fichier d'apprentissage \verb|train_2011_2012.csv| de l'énoncé du projet et réecrit un fichier \verb|train_data.csv| similaire dans lequel toutes les valeurs manquantes ont été remplacées par les moyennes ;
        \item \verb|sums_calculator.py| lit \verb|train_data.csv|, aggrège les données par date et \verb|ASS_ASSIGNMENT| et les stocke dans \verb|sums.csv| ;
        \item \verb|meteo_mean_calculator.py| agrège les données météo de \verb|meteo_2011.csv| et \verb|meteo_2012.csv| et les stocke dans \verb|meteo_means.csv| ;
        \item \verb|infer_missing_meteo_values.py| lit \verb|meteo_means.csv|, remplace les valeurs manquantes par les moyenne et stocke les résultats dans \verb|meteo_cleaned.csv| ;
        \item \verb|learning.csv| effectue de la \emph{5-fold cross-validation} sur plusieurs estimateurs et affiche les scores de précision ;
        \item \verb|data_filler.csv| définit des fonctions permettant de calculer le modèle et de prédire les données manquantes de \verb|submission.txt|.
    \end{itemize}

    \section{Résultats}
    \label{discussion}
    \paragraph{Final} Notre meilleur résultat a été obtenu sans les données météo et avec un \emph{Random Forest Classifier}. Voici les résultats de la \emph{cross-validation} :
        \begin{center}
            \begin{tabular}{c|ccccc}
                Échantillon de test&1&2&3&4&5\\\hline
                Score&$0.84404486$&$0.8495588$&$0.84760277$&$0.84870228$&$0.8481004$
            \end{tabular}
        \end{center}
        La soumission associée nous a valu un score de $113.8$ sur le \emph{leaderboard}. Voici la sortie de notre script de prédiction :
    \begin{verbatim}
Taille de X_raw : (1831665, 68)
Lecture du fichier CSV de données téléphoniques
Nombre de lignes lues : 33303
durée : 0:00:03.190759

Durée de chargement des données d'entrainement : 0:00:03.190831

Lecture du fichier submission.txt
Date : 2012-01-03 00:00:00.000
aille de X_test : (1037, 67)
Début de l'entrainement
Taille de y_test : (1037,)
0.0
1.0
0.0
0.0
0.0
0.0
0.0
5.0
...
0.0
0.0

Durée d'entrainement : 0:01:39.133896
Durée de prédiction : 0:00:00.082513
Durée totale pour cette date : 0:01:44.257681
Date : 2012-02-08 00:00:00.000
Taille de X_test : (1115, 67)
Début de l'entrainement
Taille de y_test : (1115,)
0.0
0.0
...
    \end{verbatim}
    On peut voir que le calcul est assez rapide, prenant 30 secondes au total pour faire toutes les prédictions

    \paragraph{Essais : regression} Nous avons d'abord essayé de faire une régression (par descente de gradient par exemple) sur les données téléphoniques uniquement, puis en rajoutant la météo. Cette métthode n'a pas été concluante car les prédictions ne tenaient pas compte du cycle jour/nuit, prenaient des valeurs négatives et souvaent trop élevées. La cross-validation donnait alors des valeurs abérrantes.

    \paragraph{Essais : classification} Nous avons ensuite tenté de faire de la classification avec les données météo et téléphoniques. Néanmoins, en présence des données météo les prédictions étaient toujours aberrantes, donnant un nombre d'appel constant quelque soit la date et l'heure en fonction des départements. Nous avons donc retiré les données météo et après plusieurs essais de classifieurs, avons obtenu notre meilleur résultat avec le \emph{Random Forest Classifier}.
\end{document}
